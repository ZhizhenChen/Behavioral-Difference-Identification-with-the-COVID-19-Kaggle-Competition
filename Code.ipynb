{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as data_utils\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a39ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"C:\\\\Users\\\\HUAWEI\\\\Downloads\\\\train.csv\")\n",
    "df_test = pd.read_csv(\"C:\\\\Users\\\\HUAWEI\\\\Downloads\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "034eafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_train[df_train['label'] == 1]\n",
    "df_0 = df_train[df_train['label'] == 0]\n",
    "df_1 = df_1.sample(n=2000, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
    "df_train = pd.concat([df_0,df_1],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "457304d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val,Epoch [1/6], Loss: 0.6409,Accuracy:0.8125\n",
      "val,Epoch [2/6], Loss: 0.4922,Accuracy:0.875\n",
      "val,Epoch [3/6], Loss: 0.2645,Accuracy:1.0\n",
      "val,Epoch [4/6], Loss: 0.1201,Accuracy:1.0\n",
      "val,Epoch [5/6], Loss: 0.0642,Accuracy:1.0\n",
      "val,Epoch [6/6], Loss: 0.0418,Accuracy:1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1,hidden_size2, output_size):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = out.squeeze(-1)\n",
    "        return out\n",
    "\n",
    "input_size = 4\n",
    "hidden_size1 = 10\n",
    "hidden_size2 = 10\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "batch_size = 128\n",
    "num_epochs = 6\n",
    "\n",
    "# generate data\n",
    "X = df_train.iloc[:,:4]\n",
    "y = df_train.iloc[:,4]\n",
    "\n",
    "X = (X - X.mean())/X.std()\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1,random_state = 42)\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "X_unknown_test = df_test.iloc[:,:4]\n",
    "X_unknown_test = X_unknown_test.to_numpy()\n",
    "X_unknown_test = torch.tensor(X_unknown_test, dtype=torch.float32)\n",
    "X_unknown_test = (X_unknown_test - X_unknown_test.mean())/X_unknown_test.std()\n",
    "\n",
    "# create data loader\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train,y_train)\n",
    "val_dataset =torch.utils.data.TensorDataset(X_test,y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "bn = nn.BatchNorm1d(num_features=4, track_running_stats=False)\n",
    "\n",
    "# initialize model and optimizer\n",
    "model = TwoLayerNet(input_size, hidden_size1,hidden_size2, output_size)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# define the loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "accuracy = 0\n",
    "for epoch in range(num_epochs):\n",
    "    l= []\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # forward pass\n",
    "        inputs = bn(inputs)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(val_loader):  \n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        # test the model\n",
    "        with torch.no_grad():\n",
    "            inputs = bn(inputs)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            l.append(loss.item())\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f\"val,Epoch [{epoch+1}/{num_epochs}], Loss: {np.mean(l):.4f},Accuracy:{accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c51e869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2936"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_unknown_test = bn(X_unknown_test)\n",
    "    outputs = model(X_unknown_test)\n",
    "    predicted = (outputs > 0.5).float()\n",
    "    pp = predicted.tolist()\n",
    "\n",
    "# Generalize result\n",
    "\n",
    "test_id = df_test.iloc[:,4].to_numpy()\n",
    "\n",
    "df_result = pd.DataFrame(test_id,columns = ['example_id'])\n",
    "pp = list(map(int, pp[:]))\n",
    "df_result['prediction'] = pp\n",
    "\n",
    "df_result.to_csv('test_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
